@article{Delp2009,
author = {Delp, Edward and Memon, Nasir and Wu, Min},
doi = {10.1109/MSP.2008.931089},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {2},
pages = {14--15},
title = {{Digital forensics [From the Guest Editors]}},
volume = {26},
year = {2009}
}

@article{Pearson1997,
abstract = {Technical Report CSD-TR-97-15},
author = {Pearson, Justin and Jeavons, Peter},
pages = {1--42},
title = {{A Survey of Tractable Constraint Satisfaction Problems}},
year = {1997}
}

@article{Rossi2006,
author = {Rossi, F. and Beek, P. Van and Walsh, T.},
editor = {{J. Hendler, H. Kitano}, B. Nebel},
isbn = {0444527265},
issn = {0444527265},
keywords = {F. Rossi,P. Van Beek,T. Walsh},
pages = {281--322},
title = {{Handbook of Constraint Programming (Foundations of Artificial Intelligence)}},
year = {2006}
}

@article{Garfinkel2010,
abstract = {Today's Golden Age of computer forensics is quickly coming to an end. Without a clear strategy for enabling research efforts that build upon one another, forensic research will fall behind the market, tools will become increasingly obsolete, and law enforcement, military and other users of computer forensics products will be unable to rely on the results of forensic analysis. This article summarizes current forensic research directions and argues that to move forward the community needs to adopt standardized, modular approaches for data representation and forensic processing. {\textcopyright} 2010 Digital Forensic Research Workshop. Published by Elsevier Ltd. All rights reserved.},
author = {Garfinkel, Simson L.},
doi = {10.1016/j.diin.2010.05.009},
isbn = {1742-2876},
issn = {17422876},
journal = {Digital Investigation},
keywords = {Corpora,Forensics,Human subjects research,Real data corpus,Realistic data},
number = {SUPPL.},
title = {{Digital forensics research: The next 10 years}},
volume = {7},
year = {2010}
}

@misc{Knuth1997,
abstract = {This magnificent tour de force presents a comprehensive overview of a wide variety of algorithms and the analysis of them. Now in its third edition, The Art of Computer Programming, Volume I: Fundamental Algorithms contains substantial revisions by the author and includes numerous new exercises. Although this book was conceived several decades ago, it is still a timeless classic. One of the book's greatest strengths is the wonderful collection of problems that accompany each chapter. The author has chosen problems carefully and indexed them according to difficulty. Solving a substantial number of these problems will help you gain a solid understanding of the issues surrounding the given topic. Furthermore, the exercises feature a variety of classic problems. Fundamental Algorithms begins with mathematical preliminaries. The first section offers a good grounding in a variety of useful mathematical tools: proof techniques, combinatorics, and elementary number theory. Knuth then details the MIX processor, a virtual machine architecture that serves as the programming target for subsequent discussions. This wonderful section comprehensively covers the principles of simple machine architecture, beginning with a register-level discussion of the instruction set. A later discussion of a simulator for this machine includes an excellent description of the principles underlying the implementation of subroutines and co-routines. Implementing such a simulator is an excellent introduction to computer design. In the second section, Knuth covers data structures-stacks, queues, lists, arrays, and trees-and presents implementations (in MIX assembly) along with techniques for manipulating these structures. Knuth follows many of the algorithms with careful time and space analysis. In the section on tree structures, the discussion includes a series of interesting problems concerning the combinatorics of trees (counting distinct trees of a particular form, for example) and some particularly interesting applications. Also featured is a discussion of Huffmann encoding and, in the section on lists, an excellent introduction to garbage collection algorithms and the difficult challenges associated with such a task. The book closes with a discussion of dynamic allocation algorithms. The clear writing in Fundamental Algorithms is enhanced by Knuth's dry humor and the historical discussions that accompany the technical matter. Overall, this text is one of the great classics of computer programming literature-it's not an easy book to grasp, but one that any true programmer will study with pleasure.},
author = {Knuth, Donald E.},
booktitle = {Journal of the American Statistical Association},
doi = {10.2307/2283757},
isbn = {0201896834},
issn = {01621459},
pages = {401},
title = {{The Art of Computer Programming, Vol. 1: Fundamental Algorithms}},
url = {http://www.amazon.com/dp/0201896834},
volume = {1},
year = {1997}
}

@book{Dechter2003,
abstract = {Constraint satisfaction is a simple but powerful tool. Constraints identify the impossible and reduce the realm of possibilities to effectively focus on the possible, allowing for a natural declarative formulation of what must be satisfied, without expressing how. The field of constraint reasoning has matured over the last three decades with contributions from a diverse community of researchers in artificial intelligence, databases and programming languages, operations research, management science, and applied mathematics. Today, constraint problems are used to model cognitive tasks in vision, language comprehension, default reasoning, diagnosis, scheduling, temporal and spatial reasoning. In Constraint Processing, Rina Dechter, synthesizes these contributions, along with her own significant work, to provide the first comprehensive examination of the theory that underlies constraint processing algorithms. Throughout, she focuses on fundamental tools and principles, emphasizing the representation and analysis of algorithms. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
author = {Dechter, Rina},
booktitle = {Constraint Processing},
doi = {10.1016/B978-1-55860-890-0.X5000-2},
isbn = {9781558608900},
issn = {0254-4156},
pages = {1--481},
title = {{Constraint Processing}},
year = {2003}
}

@article{Tyugu2011,
abstract = {The speed of processes and the amount of data to be used in defending the cyber space cannot be handled by humans without considerable automation. However, it is difficult to develop software with conventional fixed algorithms (hard-wired logic on decision making level) for effectively defending against the dynamically evolving attacks in networks. This situation can be handled by applying methods of artificial intelligence that provide flexibility and learning capability to software. This paper presents a brief survey of artificial intelligence applications in cyber defense (CD), and analyzes the prospects of enhancing the cyber defense capabilities by means of increasing the intelligence of the defense systems. After surveying the papers available about artificial intelligence applications in CD, we can conclude that useful applications already exist. They belong, first of all, to applications of artificial neural nets in perimeter defense and some other CD areas. From the other side - it has become obvious that many CD problems can be solved successfully only when methods of artificial intelligence are being used. For example, wide knowledge usage is necessary in decision making, and intelligent decision support is one of yet unsolved problems in CD.},
author = {Tyugu, Enn},
isbn = {978-1-61284-245-5},
issn = {2325-5366},
journal = {2011 3rd International Conference on Cyber Conflict},
keywords = {applied artificial intelligence,expert systems in cyber defense,intelligent cyber defense methods,neural nets in cyber defense},
pages = {1--11},
title = {{Artificial intelligence in cyber defense}},
year = {2011}
}

@book{Lecoutre2010,
abstract = {Constraint-based reasoning is a paradigm for formulating knowledge as a set of constraints without specifying the method by which these constraints are to be satisfied. A variety of techniques have been developed for finding partial or complete solutions for different kinds of constraint expressions. These have been successfully applied to diverse tasks such as design, diagnosis, truth maintenance, scheduling, spatiotemporal reasoning, logic programming and user interface. Constraint networks...},
author = {Lecoutre, Christophe},
booktitle = {Constraint Networks: Techniques and Algorithms},
doi = {10.1002/9780470611821},
isbn = {9781848211063},
issn = {00189340},
title = {{Constraint Networks: Techniques and Algorithms}},
year = {2010}
}

@article{Salgueiro2011,
author = {Salgueiro, Pedro and Diaz, Daniel and Brito, Isabel and Abreu, Salvador},
doi = {10.1007/978-3-642-18378-2_11},
isbn = {9783642183775},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Constraint Programming,Domain Specific Languages,Intrusion Detection Systems},
pages = {115--129},
title = {{Using constraints for intrusion detection: The NeMODe system}},
volume = {6539 LNCS},
year = {2011}
}

@online{FTK,
author = {AccessData},
title = {Forensic ToolKit},
year = {2017},
url = {https://accessdata.com/products-services/forensic-toolkit-ftk/},
urldate = {2017-12-04}
}

@online{EnCase,
author = {Guidance Software},
title = {EnCase Forensic},
year = {2017},
url = {https://www.guidancesoftware.com/encase-forensic},
urldate = {2017-12-04}
}

@online{Autopsy,
author = {Brian Carrier},
title = {Autopsy - The Sleuth Kit},
year = {2017},
url = {https://www.sleuthkit.org/autopsy/},
urldate = {2017-12-04}
}

@online{tsk,
author = {Brian Carrier},
title = {The Sleuth Kit},
year = {2017},
url = {https://www.sleuthkit.org/},
urldate = {2018-01-10}
}

@manual{chocoSolver,
  author        = {Charles Prud'homme and Jean-Guillaume Fages and Xavier Lorca},
  title         = {Choco Solver Documentation},
  year          = {2016},
  organization  = {TASC, INRIA Rennes, LINA CNRS UMR 6241, COSLING S.A.S.},
  timestamp     = {Tue, 9 Feb 2016},
  url           = {http://www.choco-solver.org }
}

@Misc{gecode,
  author = "{Gecode Team}",
  title = "Gecode: Generic Constraint Development Environment",
  year = {2006},
  url = {http://www.gecode.org}
}

@InCollection{MPG:M:5.1.0,
   Author =    "Christian Schulte and Guido Tack and Mikael Z. Lagerkvist",
   Title =     "Modeling",
   Editor =    "Christian Schulte and Guido Tack and Mikael Z. Lagerkvist",
   Booktitle = "Modeling and Programming with Gecode",
   Year =      2017,
   Note =      "Corresponds to Gecode 5.1.0"
}

@Misc{ORTools,
    author = {Google},
    title = {Google Optimization Tools We Page},
    Year = {2017},
    url = {https://developers.google.com/optimization/}
}

@Misc{Propagator,
    author = {Choco-Solver},
    title = {Class Propagator API},
    Year = {2018},
    url = {http://www.choco-solver.org/apidocs/org/chocosolver/solver/constraints/Propagator.html}
}

@Misc{SetVar,
    author = {Choco-Solver},
    title = {Interface SetVar API},
    Year = {2018},
    url = {http://www.choco-solver.org/apidocs/org/chocosolver/solver/variables/SetVar.html}
}

@Misc{H2Performance,
    author = {H2},
    title = {Performance Comparison},
    Year = {2018},
    url = {http://www.h2database.com/html/performance.html}
}

@Misc{H2Features,
    author = {H2},
    title = {Feature List},
    Year = {2018},
    url = {http://www.h2database.com/html/features.html}
}

@Misc{Unix4j,
    author = {Terzer, Marco and Warner, Ben },
    title = {Unix4j},
    Year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    url = {https://github.com/tools4j/unix4j}
}

@Misc{LinuxLEO,
    author = {Grundy, Barry J.},
    title = {The Law Enforcement and Forensic Examiner's Introduction to Linux},
    Year = {2017},
    publisher = {Linux LEO},
    journal = {Linux LEO webpage},
    url = {https://linuxleo.com/}
}

@Misc{DCorpora,
    author = {Digital Corpora},
    title = {NPS Test Disk Images},
    Year = {2018},
    publisher = {Digital Corpora},
    journal = {Digital Corpora webpage},
    url = {http://digitalcorpora.org/corpora/disk-images}
}