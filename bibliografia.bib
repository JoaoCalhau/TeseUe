@misc{FTK,
author = {AccessData},
title = {Forensic ToolKit},
year = {2017},
url = {https://accessdata.com/products-services/forensic-toolkit-ftk/},
urldate = {2017-12-04}
}

@misc{EnCase,
author = {Guidance Software},
title = {EnCase Forensic},
year = {2017},
url = {https://www.guidancesoftware.com/encase-forensic},
urldate = {2017-12-04}
}

@misc{Autopsy,
author = {Brian Carrier},
title = {Autopsy - The Sleuth Kit},
year = {2017},
url = {https://www.sleuthkit.org/autopsy/},
urldate = {2017-12-04}
}

@misc{tsk,
author = {Brian Carrier},
title = {The Sleuth Kit},
year = {2017},
url = {https://www.sleuthkit.org/},
urldate = {2018-01-10}
}

@misc{chocoSolver,
  author        = {Charles Prud'homme and Jean-Guillaume Fages and Xavier Lorca},
  title         = {Choco Solver Documentation},
  year          = {2016},
  organization  = {TASC, INRIA Rennes, LINA CNRS UMR 6241, COSLING S.A.S.},
  timestamp     = {Tue, 9 Feb 2016},
  url           = {http://www.choco-solver.org }
}

@Misc{gecode,
  author = "{Gecode Team}",
  title = "Gecode: Generic Constraint Development Environment",
  year = {2006},
  url = {http://www.gecode.org}
}

@Misc{ORTools,
    author = {Google},
    title = {Google Optimization Tools Web Page},
    Year = {2017},
    url = {https://developers.google.com/optimization/}
}

@Misc{Propagator,
    author = {Choco-Solver},
    title = {Class Propagator API},
    Year = {2018},
    url = {http://www.choco-solver.org/apidocs/org/chocosolver/solver/constraints/Propagator.html}
}

@Misc{SetVar,
    author = {Choco-Solver},
    title = {Interface SetVar API},
    Year = {2018},
    url = {http://www.choco-solver.org/apidocs/org/chocosolver/solver/variables/SetVar.html}
}

@Misc{H2Performance,
    author = {H2},
    title = {Performance Comparison},
    Year = {2018},
    url = {http://www.h2database.com/html/performance.html}
}

@Misc{H2Features,
    author = {H2},
    title = {Feature List},
    Year = {2018},
    url = {http://www.h2database.com/html/features.html}
}

@Misc{Unix4j,
    author = {Terzer, Marco and Warner, Ben },
    title = {Unix4j},
    Year = {2018},
    publisher = {GitHub},
    journal = {GitHub repository},
    url = {https://github.com/tools4j/unix4j}
}

@Misc{LinuxLEO,
    author = {Grundy, Barry J.},
    title = {The Law Enforcement and Forensic Examiner's Introduction to Linux},
    Year = {2017},
    publisher = {Linux LEO},
    journal = {Linux LEO webpage},
    url = {https://linuxleo.com/}
}

@Misc{DCorpora,
    author = {Digital Corpora},
    title = {NPS Test Disk Images},
    Year = {2018},
    publisher = {Digital Corpora},
    journal = {Digital Corpora webpage},
    url = {http://digitalcorpora.org/corpora/disk-images}
}

@article{schulte2010modeling,
  title={Modeling and programming with gecode},
  author={Schulte, Christian and Tack, Guido and Lagerkvist, Mikael Z},
  journal={Schulte, Christian and Tack, Guido and Lagerkvist, Mikael},
  volume={2015},
  year={2010}
}

@book{rossi2006handbook,
  title={Handbook of constraint programming},
  author={Rossi, Francesca and Van Beek, Peter and Walsh, Toby},
  year={2006},
  publisher={Elsevier}
}

@article{Park2009,
abstract = {We developed Cyber Forensics Ontology for the criminal investigation in cyber space. Cyber crime is classified into cyber terror and general cyber crime, and those two classes are connected with each other. The investigation of cyber terror requires high technology, system environment and experts, and general cyber crime is connected with general crime by evidence from digital data and cyber space. Accordingly, it is difficult to determine relational crime types and collect evidence. Therefore, we considered the classifications of cyber crime, the collection of evidence in cyber space and the application of laws to cyber crime. In order to efficiently investigate cyber crime, it is necessary to integrate those concepts for each cyber crime-case. Thus, we constructed a cyber forensics domain ontology for criminal investigation in cyber space, according to the categories of cyber crime, laws, evidence and information of criminals. This ontology can be used in the process of investigating of cyber crime-cases, and for data mining of cyber crime; classification, clustering, association and detection of crime types, crime cases, evidences and criminals.},
author = {Park, Heum and Cho, SunHo and Kwon, Hyuk Chul},
doi = {10.1007/978-3-642-02312-5_18},
file = {::},
isbn = {3642023118},
issn = {18678211},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
keywords = {Criminal investigation,Cyber crime,Cyber forensics,Digital evidence,Ontology},
pages = {160--165},
title = {{Cyber forensics ontology for cyber criminal investigation}},
volume = {8 LNICST},
year = {2009}
}

@article{Pearson1997,
abstract = {Technical Report CSD-TR-97-15},
author = {Pearson, Justin and Jeavons, Peter},
file = {::},
pages = {1--42},
title = {{A Survey of Tractable Constraint Satisfaction Problems}},
journal = {{Technical Report CSD-TR-97-15, Royal Holloway, University of London}},
year = {1997}
}

@article{Delp2009,
author = {Delp, Edward and Memon, Nasir and Wu, Min},
doi = {10.1109/MSP.2008.931089},
file = {::},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {2},
pages = {14--15},
title = {{Digital forensics [From the Guest Editors]}},
volume = {26},
year = {2009}
}

@article{Garfinkel2010,
abstract = {Today's Golden Age of computer forensics is quickly coming to an end. Without a clear strategy for enabling research efforts that build upon one another, forensic research will fall behind the market, tools will become increasingly obsolete, and law enforcement, military and other users of computer forensics products will be unable to rely on the results of forensic analysis. This article summarizes current forensic research directions and argues that to move forward the community needs to adopt standardized, modular approaches for data representation and forensic processing. {\textcopyright} 2010 Digital Forensic Research Workshop. Published by Elsevier Ltd. All rights reserved.},
author = {Garfinkel, Simson L.},
doi = {10.1016/j.diin.2010.05.009},
file = {::},
isbn = {1742-2876},
issn = {17422876},
journal = {Digital Investigation},
keywords = {Corpora,Forensics,Human subjects research,Real data corpus,Realistic data},
number = {SUPPL.},
title = {{Digital forensics research: The next 10 years}},
volume = {7},
publisher = {Elsevier},
year = {2010}
}

@book{Knuth1973,
abstract = {Immunohistochemical markers are often used to classify breast cancer into subtypes that are biologically distinct and behave differently. The aim of this study was to estimate relapse for patients with the major subtypes of breast cancer as classified using immunohistochemical assay and to investigate the patterns of benefit from the therapies over the past years. The study population included primary, operable 2,118 breast cancer patients, all non-specific infiltrative ductal carcinoma, with the median age of 53.2years. All patients underwent local and/or systemic treatments. The clinicopathological characteristics and clinical outcomes were retrospectively reviewed. The expression of estrogen receptor (ER), progesterone receptor, human epidermal growth factor receptor 2 (HER2), epidermal growth factor receptor (EGFR), and cytokeratin 5/6 were analyzed by immunohistochemistry. All patients were classified into the following categories: luminal A, luminal B, HER2 overexpressing, basal-like, and unclassified subtypes. Ki-67 was detected in luminal A subtype. The median follow-up time was 67.9months. Luminal A tumors had the lowest rate of relapse (12.7{\%}, P{\textless}0.001), while luminal B, HER2 overexpression, and basal-like subtypes were associated with an increased risk of relapse (15.7, 19.1, 20.9{\%}). Molecular subtypes retained independent prognostic significance (P{\textless}0.001). In luminal A subtype, adjunctive radiotherapy could decrease the risk of relapse (P=0.005), Ki67 positive was a high-risk factor for relapse (P{\textless}0.001), and adjuvant chemotherapies could reduce the relapse for the patients with risk factors (P{\textless}0.001). Adjuvant hormone therapy was an effective treatment for ER-positive tumors (P{\textless}0.001). Molecular subtypes of breast cancer could robustly identify the risk of recurrence and were significant in therapeutic decision making. The model combined subtype and clinical pathology was a significant improvement. Luminal A tumors might represent two distinct subsets which demonstrated distinct prognosis and therapy response.},
author = {Knuth, Donald E},
booktitle = {Reading MA},
doi = {10.2307/2283757},
isbn = {0201038226},
issn = {00255718},
number = {116},
pages = {401},
pmid = {21837481},
title = {{The Art of Computer Programming}},
url = {http://neerc.ifmo.ru/school/io/archive/20090516/problems-advanced-07.pdf},
volume = {2},
year = {1973}
}

@book{Dechter2003,
abstract = {Constraint satisfaction is a simple but powerful tool. Constraints identify the impossible and reduce the realm of possibilities to effectively focus on the possible, allowing for a natural declarative formulation of what must be satisfied, without expressing how. The field of constraint reasoning has matured over the last three decades with contributions from a diverse community of researchers in artificial intelligence, databases and programming languages, operations research, management science, and applied mathematics. Today, constraint problems are used to model cognitive tasks in vision, language comprehension, default reasoning, diagnosis, scheduling, temporal and spatial reasoning. In Constraint Processing, Rina Dechter, synthesizes these contributions, along with her own significant work, to provide the first comprehensive examination of the theory that underlies constraint processing algorithms. Throughout, she focuses on fundamental tools and principles, emphasizing the representation and analysis of algorithms. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
author = {Dechter, Rina},
booktitle = {Constraint Processing},
doi = {10.1016/B978-1-55860-890-0.X5000-2},
isbn = {9781558608900},
issn = {0254-4156},
pages = {1--481},
title = {{Constraint Processing}},
publisher = {Morgan Kaufmann},
year = {2003}
}

@misc{Knuth1997,
abstract = {This magnificent tour de force presents a comprehensive overview of a wide variety of algorithms and the analysis of them. Now in its third edition, The Art of Computer Programming, Volume I: Fundamental Algorithms contains substantial revisions by the author and includes numerous new exercises. Although this book was conceived several decades ago, it is still a timeless classic. One of the book's greatest strengths is the wonderful collection of problems that accompany each chapter. The author has chosen problems carefully and indexed them according to difficulty. Solving a substantial number of these problems will help you gain a solid understanding of the issues surrounding the given topic. Furthermore, the exercises feature a variety of classic problems. Fundamental Algorithms begins with mathematical preliminaries. The first section offers a good grounding in a variety of useful mathematical tools: proof techniques, combinatorics, and elementary number theory. Knuth then details the MIX processor, a virtual machine architecture that serves as the programming target for subsequent discussions. This wonderful section comprehensively covers the principles of simple machine architecture, beginning with a register-level discussion of the instruction set. A later discussion of a simulator for this machine includes an excellent description of the principles underlying the implementation of subroutines and co-routines. Implementing such a simulator is an excellent introduction to computer design. In the second section, Knuth covers data structures-stacks, queues, lists, arrays, and trees-and presents implementations (in MIX assembly) along with techniques for manipulating these structures. Knuth follows many of the algorithms with careful time and space analysis. In the section on tree structures, the discussion includes a series of interesting problems concerning the combinatorics of trees (counting distinct trees of a particular form, for example) and some particularly interesting applications. Also featured is a discussion of Huffmann encoding and, in the section on lists, an excellent introduction to garbage collection algorithms and the difficult challenges associated with such a task. The book closes with a discussion of dynamic allocation algorithms. The clear writing in Fundamental Algorithms is enhanced by Knuth's dry humor and the historical discussions that accompany the technical matter. Overall, this text is one of the great classics of computer programming literature-it's not an easy book to grasp, but one that any true programmer will study with pleasure.},
author = {Knuth, Donald E.},
booktitle = {Journal of the American Statistical Association},
doi = {10.2307/2283757},
isbn = {0201896834},
issn = {01621459},
pages = {401},
title = {{The Art of Computer Programming, Vol. 1: Fundamental Algorithms}},
url = {http://www.amazon.com/dp/0201896834},
volume = {1},
year = {1997}
}
@article{Tyugu2011,
abstract = {The speed of processes and the amount of data to be used in defending the cyber space cannot be handled by humans without considerable automation. However, it is difficult to develop software with conventional fixed algorithms (hard-wired logic on decision making level) for effectively defending against the dynamically evolving attacks in networks. This situation can be handled by applying methods of artificial intelligence that provide flexibility and learning capability to software. This paper presents a brief survey of artificial intelligence applications in cyber defense (CD), and analyzes the prospects of enhancing the cyber defense capabilities by means of increasing the intelligence of the defense systems. After surveying the papers available about artificial intelligence applications in CD, we can conclude that useful applications already exist. They belong, first of all, to applications of artificial neural nets in perimeter defense and some other CD areas. From the other side - it has become obvious that many CD problems can be solved successfully only when methods of artificial intelligence are being used. For example, wide knowledge usage is necessary in decision making, and intelligent decision support is one of yet unsolved problems in CD.},
author = {Tyugu, Enn},
file = {::},
isbn = {978-1-61284-245-5},
issn = {2325-5366},
journal = {2011 3rd International Conference on Cyber Conflict},
keywords = {applied artificial intelligence,expert systems in cyber defense,intelligent cyber defense methods,neural nets in cyber defense},
pages = {1--11},
title = {{Artificial intelligence in cyber defense}},
year = {2011}
}
@book{Lecoutre2010,
abstract = {Constraint-based reasoning is a paradigm for formulating knowledge as a set of constraints without specifying the method by which these constraints are to be satisfied. A variety of techniques have been developed for finding partial or complete solutions for different kinds of constraint expressions. These have been successfully applied to diverse tasks such as design, diagnosis, truth maintenance, scheduling, spatiotemporal reasoning, logic programming and user interface. Constraint networks...},
author = {Lecoutre, Christophe},
booktitle = {Constraint Networks: Techniques and Algorithms},
doi = {10.1002/9780470611821},
isbn = {9781848211063},
issn = {00189340},
title = {{Constraint Networks: Techniques and Algorithms}},
publisher = {John Wiley \& Sons},
year = {2010}
}
@article{Salgueiro2011,
author = {Salgueiro, Pedro and Diaz, Daniel and Brito, Isabel and Abreu, Salvador},
doi = {10.1007/978-3-642-18378-2_11},
file = {::},
isbn = {9783642183775},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Constraint Programming,Domain Specific Languages,Intrusion Detection Systems},
pages = {115--129},
title = {{Using constraints for intrusion detection: The NeMODe system}},
volume = {6539 LNCS},
year = {2011}
}
@article{Garfinkel2010a,
abstract = {Today's Golden Age of computer forensics is quickly coming to an end. Without a clear strategy for enabling research efforts that build upon one another, forensic research will fall behind the market, tools will become increasingly obsolete, and law enforcement, military and other users of computer forensics products will be unable to rely on the results of forensic analysis. This article summarizes current forensic research directions and argues that to move forward the community needs to adopt standardized, modular approaches for data representation and forensic processing. {\textcopyright} 2010 Digital Forensic Research Workshop. Published by Elsevier Ltd. All rights reserved.},
author = {Garfinkel, Simson L.},
doi = {10.1016/j.diin.2010.05.009},
isbn = {1742-2876},
issn = {17422876},
journal = {Digital Investigation},
keywords = {Corpora,Forensics,Human subjects research,Real data corpus,Realistic data},
title = {{Digital forensics research: The next 10 years}},
year = {2010}
}

@article{Menger1954,
author = {Menger, Karl},
doi = {10.1093/bjps/V.18.134},
isbn = {0521265304},
issn = {00070882},
journal = {British Journal for the Philosophy of Science},
title = {{On variables in mathematics and in natural science}},
year = {1954}
}
@book{Apt2003,
abstract = {Scheduling, vehicle routing and timetabling are all examples of constraint problems, and methods to solve them rely on the idea of constraint propagation and search. This book meets the need for a modern, multidisciplinary introduction to the field that covers foundations and applications. Written by Krzysztof Apt, an authority on the subject, it will be welcomed by graduate students and professionals. With the insertion of constraint techniques into programming environments, new developments have accelerated the solution process. Constraint programming combines ideas from artificial intelligence, programming languages, databases, and operational research. Constraints are everywhere: most computational problems can be described in terms of restrictions imposed on the set of possible solutions, and constraint programming is a problem-solving technique that works by incorporating those restrictions in a programming environment. It draws on methods from combinatorial optimization and artificial intelligence, and has been successfully applied in a number of fields from scheduling, computational biology, finance, electrical engineering and operations research through to numerical analysis. This textbook for upper-division students provides a thorough and structured account of the main aspects of constraint programming. The author provides many worked examples that illustrate the usefulness and versatility of this approach to programming, as well as many exercises throughout the book that illustrate techniques, test skills and extend the text. Pointers to current research, extensive historical and bibliographic notes, and a comprehensive list of references will also be valuable to professionals in computer science and artificial intelligence.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Apt, Krzysztof R},
booktitle = {Annals of Physics},
doi = {10.2277/0521825830},
eprint = {arXiv:1011.1669v3},
isbn = {0521825830},
issn = {1098-6596},
pmid = {25246403},
title = {{Principles of Constraint Programming}},
publisher = {Cambridge},
year = {2003}
}

@book{hahn1921theorie,
  title={Theorie der reellen Funktionen},
  author={Hahn, Hans},
  volume={1},
  year={1921},
  publisher={Julius Springer}
}

@article{freuder1978synthesizing,
  title={Synthesizing constraint expressions},
  author={Freuder, Eugene C},
  journal={Communications of the ACM},
  volume={21},
  number={11},
  pages={958--966},
  year={1978},
  publisher={ACM}
}

@article{jussien2002local,
  title={Local search with constraint propagation and conflict-based heuristics},
  author={Jussien, Narendra and Lhomme, Olivier},
  journal={Artificial Intelligence},
  volume={139},
  number={1},
  pages={21--45},
  year={2002}
}

@article{lin1965computer,
  title={Computer solutions of the traveling salesman problem},
  author={Lin, Shen},
  journal={Bell System Technical Journal},
  volume={44},
  number={10},
  pages={2245--2269},
  year={1965},
  publisher={Wiley Online Library}
}

@book{holland1992adaptation,
  title={Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence},
  author={Holland, John Henry},
  year={1992},
  publisher={MIT press}
}

@inproceedings{bessiere2001refining,
  title={Refining the Basic Constraint Propagation Algorithm.},
  author={Bessi{\`e}re, Christian and R{\'e}gin, Jean-Charles},
  booktitle={IJCAI},
  volume={1},
  pages={309--315},
  year={2001}
}

@article{freuder1985sufficient,
  title={A sufficient condition for backtrack-bounded search},
  author={Freuder, Eugene C},
  journal={Journal of the ACM (JACM)},
  volume={32},
  number={4},
  pages={755--761},
  year={1985},
  publisher={ACM}
}

@article{quine1960variables,
  title={Variables explained away},
  author={Quine, Willard V},
  journal={Proceedings of the american philosophical society},
  volume={104},
  number={3},
  pages={343--347},
  year={1960},
  publisher={JSTOR}
}

@book{miranda2012partial,
  title={Partial differential equations of elliptic type},
  author={Miranda, Carlo},
  volume={2},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@book{philipp2009hacking,
  title={Hacking exposed computer forensics},
  author={Philipp, Aaron and Cowen, David and Davis, Chris},
  year={2009},
  publisher={McGraw-Hill, Inc.}
}

@book{mohay2003computer,
  title={Computer and intrusion forensics},
  author={Mohay, George M},
  year={2003},
  publisher={Artech House}
}

@article{sommer2004future,
  title={The future for the policing of cybercrime},
  author={Sommer, Peter},
  journal={Computer Fraud \& Security},
  volume={2004},
  number={1},
  pages={8--12},
  year={2004},
  publisher={Elsevier}
}

@misc{casey2014digital,
  title={Digital evidence and computer crime},
  author={Casey, Eoghan and Blitz, Andrew and Steuart, Christopher},
  year={2014},
  publisher={Academic Press}
}

@article{taub2006deleting,
  title={Deleting may be easy, but your hard drive still tells all},
  author={Taub, Eric A},
  journal={The New York Times News Service. Retrieved March},
  volume={17},
  pages={2008},
  year={2006}
}

@article{dixon2005overview,
  title={An overview of computer forensics},
  author={Dixon, Phillip D},
  journal={IEEE Potentials},
  volume={24},
  number={5},
  pages={7--10},
  year={2005},
  publisher={IEEE}
}

@misc{microsoft2008cofee,
author = {Benjamin J. Romano},
title = {Microsoft device helps police pluck evidence from cyberscene of crime},
year = {2008},
url = {http://old.seattletimes.com/html/microsoft/2004379751_msftlaw29.html},
urldate = {2018-07-23}
}

@misc{cofee2009leaked,
author = {Nicholas Deleon},
title = {Microsoft COFEE law enforcement tool leaks all over the Internet!},
year = {2009},
url = {https://techcrunch.com/2009/11/06/siren-gif-microsoft-cofee-law-enforcement-tool-leaks-all-over-the-internet/?guccounter=1},
urldate = {2018-07-23}
}

@misc{aboutChoco,
author={Charles Prud'homme and Jean-Guillaume Fages and Xavier Lorca},
title={About Choco Solver},
year={2016},
url={http://choco-solver.readthedocs.io/en/latest/1_overview.html#about-choco-solver},
urldate={2018-07-23}
}

@misc{historyChoco,
author={Charles Prud'homme and Jean-Guillaume Fages and Xavier Lorca},
title={History},
year={2016},
url={http://choco-solver.readthedocs.io/en/latest/1_overview.html#history},
urldate={2018-07-23}
}

@article{hoffman1969constructions,
  title={Constructions for the solution of the m queens problem},
  author={Hoffman, EJ and Loessi, JC and Moore, RC},
  journal={Mathematics Magazine},
  volume={42},
  number={2},
  pages={66--72},
  year={1969},
  publisher={Taylor \& Francis}
}

@article{rivin1994n,
  title={The n-queens problem},
  author={Rivin, Igor and Vardi, Ilan and Zimmermann, Paul},
  journal={The American Mathematical Monthly},
  volume={101},
  number={7},
  pages={629--639},
  year={1994},
  publisher={Taylor \& Francis}
}

@inproceedings{barenboim2009distributed,
  title={Distributed ($\delta$+ 1)-coloring in linear (in $\delta$) time},
  author={Barenboim, Leonid and Elkin, Michael},
  booktitle={Proceedings of the forty-first annual ACM symposium on Theory of computing},
  pages={111--120},
  year={2009},
  organization={ACM}
}

@article{provan2009sudoku,
  title={Sudoku: strategy versus structure},
  author={Provan, J Scott},
  journal={The American Mathematical Monthly},
  volume={116},
  number={8},
  pages={702--707},
  year={2009},
  publisher={Taylor \& Francis}
}

@book{ballou2010electronic,
  title={Electronic crime scene investigation: A guide for first responders},
  author={Ballou, Susan},
  year={2010},
  publisher={Diane Publishing}
}

@book{casey2009handbook,
  title={Handbook of digital forensics and investigation},
  author={Casey, Eoghan},
  year={2009},
  publisher={Academic Press}
}

@book{casey2011digital,
  title={Digital evidence and computer crime: Forensic science, computers, and the internet},
  author={Casey, Eoghan},
  year={2011},
  publisher={Academic press}
}

@article{allen2005computer,
  title={Computer forensics},
  author={Allen, William H},
  journal={IEEE security \& privacy},
  volume={3},
  number={4},
  pages={59--62},
  year={2005},
  publisher={IEEE}
}

@article{ryder2002computer,
  title={Computer Forensics - We've Had an Incident, Who Do We Get to Investigate},
  author={Ryder, Karen},
  year={2002},
  journal = {SANS Institute InfoSec Reading Room}
}

@misc{BrianFls,
author = {Brian Carrier},
title = {FLS Manual Page},
year = {2018},
url = {http://www.sleuthkit.org/sleuthkit/man/fls.html},
urldate = {2018-09-09}
}

@misc{BrianMactime,
    author = {Brian Carrier},
    title = {Mactime Manual page},
    year = {2018},
    url = {http://www.sleuthkit.org/sleuthkit/man/mactime.html},
    urldate = {2018-09-10}
}

@article{reith2002examination,
  title={An examination of digital forensic models},
  author={Reith, Mark and Carr, Clint and Gunsch, Gregg},
  journal={International Journal of Digital Evidence},
  volume={1},
  number={3},
  pages={1--12},
  year={2002}
}

@misc{siegel1998criminology,
  title={Criminology: Theories, Patterns, and Typologies},
  author={Siegel, L},
  year={1998},
  publisher={Wadsworth Publishing Company}
}

@article{bardsley2005btk,
  title={Btk kansas serial killer-full btk story},
  author={Bardsley, M and Bel, R and Lohr, D},
  journal={World Wide Web. Last accessed},
  volume={26},
  number={08},
  pages={2008},
  year={2005}
}

@book{girard2017criminalistics,
  title={Criminalistics},
  author={Girard, James E},
  year={2017},
  publisher={Jones \& Bartlett Learning}
}

@misc{alicia2013survivor,
    title = {I, too, am an abduction survivor},
    author = {Alicia Kozakiewicz},
    year = {2013},
    publisher = {CNN},
    url = {https://edition.cnn.com/2013/05/15/health/human-factor-alicia-kozakiewicz/},
    urldate = {2018-09-10}
}

@misc{nicole2007alicia,
    title = {Abducted, Enslaved—and Now Talking About It},
    author = {Nicole Weisensee Egan},
    year = {2007},
    publisher = {People},
    url = {https://people.com/archive/abducted-enslaved-and-now-talking-about-it-vol-67-no-15/},
    urldate = {2018-09-10}
}

@misc{BrianIcat,
author = {Brian Carrier},
title = {ICAT Manual Page},
year = {2018},
url = {http://www.sleuthkit.org/sleuthkit/man/icat.html},
urldate = {2018-09-20}
}

@misc{foremostUbuntu,
    author = {Ruchi},
    title = {Recover Deleted Files with Foremost, scalpel in Ubuntu},
    year = {2008},
    url = {http://www.ubuntugeek.com/recover-deleted-files-with-foremostscalpel-in-ubuntu.html},
    urldate = {2018-09-20}
}

@misc{photoRec,
    author = {CgSecurity},
    title = {File Formats Recovered by PhotoRec},
    year = {2015},
    url = {https://www.cgsecurity.org/wiki/File_Formats_Recovered_By_PhotoRec},
    urldate = {2018-09-20}
}

@misc{2018communication,
    author = {Calhau, João and Salgueiro, Pedro and Abreu, Salvador and Goes, Nuno},
    title = {Using Constraint Programming for Digital Forensics},
    year = {2018},
    publisher = {INForum 2018}
}